{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6065cdd5",
   "metadata": {},
   "source": [
    "# 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e2486358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f80385",
   "metadata": {},
   "source": [
    "# 전역 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dce79b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    data_path = \"data/\" # 데이터 경로\n",
    "    seed = 42 # 시드값\n",
    "    model_name = \"model-rnncnn\" # 모델 이름 \n",
    "    patience_limit = 5 # 조기종료 조건 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5007ad4",
   "metadata": {},
   "source": [
    "# 함수 및 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7805a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    재현성을 위한 시드고정 함수\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def train_loop(dataloader,model,loss_fn,optimizer,device):\n",
    "    \"\"\"\n",
    "    모델 학습 기능 함수\n",
    "    \"\"\"\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for batch in dataloader:\n",
    "        pred = model(batch[\"seq\"].to(device),batch[\"tb\"].to(device))\n",
    "        loss = loss_fn(pred, batch[\"y\"].to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "\n",
    "    return epoch_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_loop(dataloader,model,loss_fn,device):\n",
    "    \"\"\"\n",
    "    모델 검증 및 추론 기능 함수\n",
    "    \"\"\"\n",
    "    epoch_loss = 0\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    for batch in dataloader:\n",
    "\n",
    "        pred = model(batch[\"seq\"].to(device),batch[\"tb\"].to(device))\n",
    "        if batch.get(\"y\") is not None:\n",
    "            loss = loss_fn(pred, batch[\"y\"].to(device))\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        pred = pred.to(\"cpu\").numpy()\n",
    "        pred_list.append(pred)\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    pred = np.concatenate(pred_list)\n",
    "    return epoch_loss , pred\n",
    "\n",
    "class TorchDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    데이터셋 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self ,seq, tb , y = None):\n",
    "        self.seq = seq\n",
    "        self.tb = tb\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {}\n",
    "        item[\"seq\"] = torch.Tensor(self.seq[idx])\n",
    "        item[\"tb\"] = torch.Tensor(self.tb[idx])\n",
    "        if self.y is not None:\n",
    "            item[\"y\"] = torch.Tensor(self.y[idx])\n",
    "        return item\n",
    "    \n",
    "class ResidualBlock(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    잔차 블록 레이어 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, act):\n",
    "        super().__init__()\n",
    "        self.fx = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features, in_features),\n",
    "            act,\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(in_features, in_features)\n",
    "        )\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        fx = self.fx(x)\n",
    "        hx = fx + x\n",
    "        return self.act(hx)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    모델 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features,in_features, lstm_hidden=128, act_conv1d=\"leaky_relu\", act_init=\"leaky_relu\",act_res=\"relu\",\n",
    "                  n_layers = 4, **kwarg):\n",
    "        super().__init__()\n",
    "        self.act_dict = {\n",
    "            \"relu\" : torch.nn.ReLU(),\n",
    "            \"leaky_relu\" : torch.nn.LeakyReLU(),\n",
    "            \"prelu\" : torch.nn.PReLU(),\n",
    "            \"elu\" : torch.nn.ELU(),\n",
    "            \"silu\" : torch.nn.SiLU(),\n",
    "            \"gelu\" : torch.nn.GELU(),\n",
    "        }\n",
    "        \n",
    "        self.lstm_layer = torch.nn.LSTM(n_features, lstm_hidden, batch_first=True)   \n",
    "        self.conv1d_block = torch.nn.Sequential( # input shape: B, F, S\n",
    "            torch.nn.Conv1d(lstm_hidden, lstm_hidden*2, 3),\n",
    "            self.act_dict[act_conv1d],\n",
    "            torch.nn.MaxPool1d(2),\n",
    "            torch.nn.Conv1d(lstm_hidden*2, lstm_hidden*4, 3),\n",
    "            self.act_dict[act_conv1d],\n",
    "            torch.nn.MaxPool1d(2),\n",
    "            torch.nn.AdaptiveAvgPool1d(1), # B, F, 1\n",
    "            torch.nn.Flatten(), # B, F\n",
    "        ) \n",
    "\n",
    "        self.init_layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features, in_features // 2),\n",
    "            torch.nn.BatchNorm1d(in_features // 2),\n",
    "            self.act_dict[act_init]\n",
    "        )\n",
    "        res_list = [ ResidualBlock(in_features//2, self.act_dict[act_res]) for _ in range(n_layers) ]\n",
    "        self.res_seq = torch.nn.Sequential(*res_list)\n",
    "    \n",
    "        self.output_layer = torch.nn.Linear(lstm_hidden*4 + in_features//2, 1)\n",
    "    def forward(self, seq, tb):\n",
    "        output, (hn, cn) = self.lstm_layer(seq)\n",
    "        seq = self.conv1d_block( output.permute(0, 2, 1) )  # input/output shape: B, F, S\n",
    "        \n",
    "        tb = self.init_layer(tb)\n",
    "        tb = self.res_seq(tb)\n",
    "\n",
    "        x = torch.cat([seq,tb],dim=1)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5512c92d",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7116ec40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22176, 30), (154, 2), (9504, 30), (66, 2))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_trans = pd.read_csv(f\"{CFG.data_path}x_train.csv\")\n",
    "train_target = pd.read_csv(f\"{CFG.data_path}y_train.csv\")\n",
    "test_trans = pd.read_csv(f\"{CFG.data_path}x_test.csv\")\n",
    "submit = pd.read_csv(f\"{CFG.data_path}submission.csv\")\n",
    "\n",
    "train_trans.shape, train_target.shape, test_trans.shape, submit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057dea9",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00601e4f",
   "metadata": {},
   "source": [
    "- 2차원 피처셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e00e6433",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"DAT\", \"fan\", \"co2\", \"heater\", \"window1\", \"window2\", \"curtain1\", \"curtain2\", \"curtain3\", \"side_curtain\", \"rain_sensor\",\n",
    " \"crown_diameter\", \"petiole_length\", \"leaf_count\", \"leaf_length\",\"leaf_width\",\"fruit_count\",\"plant_height\",\n",
    " \"flower_count\",\"numbers of plant\"]\n",
    "agg_dict = {}\n",
    "for col in cols:\n",
    "    agg_dict[col] = [\n",
    "        (f\"{col}_mean\",\"mean\")\n",
    "    ]\n",
    "\n",
    "cols = [\"in_temp\",\"in_hum\",\"in_co2\",\"out_temp\",\"out_hum\",\"solar_rad\",\"wind_speed\",\"wind_direction\"]\n",
    "\n",
    "for col in cols:\n",
    "    agg_dict[col] = [\n",
    "        (f\"{col}_mean\",\"mean\"),\n",
    "        (f\"{col}_min\",\"min\"),\n",
    "        (f\"{col}_max\",\"max\"),\n",
    "        (f\"{col}_skew\",\"skew\"),\n",
    "        (f\"{col}_kurt\",lambda x: x.kurt()),\n",
    "        (f\"{col}_std\",\"std\"),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "64342193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = train_trans.groupby(\"Sample_Number\").agg(agg_dict)\n",
    "tmp.columns = tmp.columns.droplevel()\n",
    "tmp = tmp.reset_index()\n",
    "train_ft = train_target.iloc[:,:1].merge(tmp, how=\"left\", on=\"Sample_Number\").drop(columns=\"Sample_Number\")\n",
    "\n",
    "tmp = test_trans.groupby(\"Sample_Number\").agg(agg_dict)\n",
    "tmp.columns = tmp.columns.droplevel()\n",
    "tmp = tmp.reset_index()\n",
    "test_ft = submit.iloc[:,:1].merge(tmp, how=\"left\", on=\"Sample_Number\").drop(columns=\"Sample_Number\")\n",
    "train_ft.isnull().sum().sum(), test_ft.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5aaf0331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((154, 68), (66, 68))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_ft = scaler.fit_transform(train_ft)\n",
    "test_ft = scaler.transform(test_ft)\n",
    "train_ft.shape, test_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39cc8a2",
   "metadata": {},
   "source": [
    "- 3차원 피처셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d67707c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22176, 28), (9504, 28))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols = [\n",
    "    \"Sample_Number\",\"time\",\n",
    "    # \"DAT\", \"crown_diameter\", \"petiole_length\",\"leaf_count\",\"leaf_length\",\"leaf_width\",\n",
    "    # \"fruit_count\",\"plant_height\",\"flower_count\",\"numbers of plant\"\n",
    "]\n",
    "train_data = scaler.fit_transform(train_trans.drop(columns=drop_cols))\n",
    "test_data = scaler.transform(test_trans.drop(columns=drop_cols))\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "21e48673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((154, 144, 28), (66, 144, 28))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = train_data.shape[1]\n",
    "train_data = train_data.reshape(-1,144,n)\n",
    "test_data = test_data.reshape(-1,144,n)\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1effd0",
   "metadata": {},
   "source": [
    "- 정답 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4d7000e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 1)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = train_target[\"CO2 final\"].to_numpy().reshape(-1,1)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c105f2",
   "metadata": {},
   "source": [
    "- 데이터셋 클래스 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d93f28e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seq': tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
       "          [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
       "          [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]],\n",
       " \n",
       "         [[0.0083, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
       "          [0.0083, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
       "          [0.0083, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.0083, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
       "          [0.0083, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
       "          [0.0083, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]]]),\n",
       " 'tb': tensor([[0.0000, 0.4653, 0.1333, 0.5373, 1.0000, 1.0000, 0.8599, 0.9766, 0.5779,\n",
       "          0.3291, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0083, 0.0000, 0.0000,\n",
       "          0.0000, 1.0000, 0.9321, 0.7813, 0.8815, 0.3325, 0.0148, 0.5854, 0.3731,\n",
       "          0.3367, 0.4887, 0.4982, 0.0653, 0.6373, 0.1675, 0.3491, 0.0223, 0.2589,\n",
       "          0.0199, 0.0440, 0.9620, 0.8532, 0.9343, 0.2507, 0.0109, 0.5445, 0.6313,\n",
       "          0.1924, 0.7982, 0.2644, 0.1549, 0.7508, 0.9330, 0.0357, 0.9731, 0.1528,\n",
       "          0.0838, 0.9511, 0.1743, 0.0000, 0.1881, 0.1290, 0.0026, 0.3679, 0.3445,\n",
       "          0.2238, 0.4918, 0.6167, 0.0074, 0.8288],\n",
       "         [0.0083, 0.6042, 0.0667, 0.4328, 0.4211, 0.4211, 0.9759, 0.8651, 0.5779,\n",
       "          0.5560, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0083, 0.0000, 0.0000,\n",
       "          0.0000, 1.0000, 0.7847, 0.7603, 0.7895, 0.4896, 0.2182, 0.3782, 0.5834,\n",
       "          0.5659, 0.6058, 0.4662, 0.0724, 0.5128, 0.2499, 0.4992, 0.0232, 0.2295,\n",
       "          0.0204, 0.0230, 0.8753, 0.8574, 0.8336, 0.3551, 0.0512, 0.2546, 0.6465,\n",
       "          0.2982, 0.9177, 0.4292, 0.1181, 0.7146, 0.8591, 0.0357, 0.8976, 0.1725,\n",
       "          0.1063, 0.8753, 0.1005, 0.0000, 0.2277, 0.2458, 0.0491, 0.2871, 0.0661,\n",
       "          0.2159, 0.2547, 0.7319, 0.0884, 0.4484]]),\n",
       " 'y': tensor([[0.5643],\n",
       "         [1.9232]])}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = TorchDataset(train_data,train_ft ,target)\n",
    "dl = torch.utils.data.DataLoader(dt, batch_size=2, shuffle=False)\n",
    "batch = next(iter(dl))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d516a5",
   "metadata": {},
   "source": [
    "- 모델 입출력 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f49cacb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0619],\n",
       "        [-0.0129]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(train_data.shape[2], train_ft.shape[1])\n",
    "model( batch[\"seq\"], batch[\"tb\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b35165",
   "metadata": {},
   "source": [
    "# 학습\n",
    "- 학습 및 검증 과정에서 모델 가중치 저장됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "986ac9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_splits = 5 # k-fold 의 k 값\n",
    "epochs = 100\n",
    "loss_fn = torch.nn.MSELoss() \n",
    "n_features = train_data.shape[2]\n",
    "in_features = train_ft.shape[1]\n",
    "cv = StratifiedKFold(n_splits=n_splits,shuffle=True, random_state=CFG.seed) # cv 객체\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "groups = pd.qcut(target.reshape(-1),10,np.arange(10))\n",
    "hp = {\n",
    "    \"lstm_hidden\":752,\n",
    "    \"act_conv1d\":'relu',\n",
    "    \"act_init\":'silu',\n",
    "    \"act_res\":'relu',\n",
    "    \"n_layers\":4,\n",
    "    \"lr\": 0.0006,\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b8b09ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9787502ae4be44d297d4e5bc10048672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold (0), BEST RMSE: 1.5808073225798196, BEST R2: 0.8901060977870137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e97060f1794ffbba3f824aa9ef21e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold (1), BEST RMSE: 1.8126807213463094, BEST R2: 0.8458378853104638\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eef525ac4dc4490a07e2408a66851a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold (2), BEST RMSE: 1.9325174236845286, BEST R2: 0.8469955422740878\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b7b8ad2d424272a31d17e491ba8ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold (3), BEST RMSE: 1.0389782303709945, BEST R2: 0.9586458800045733\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0580a2f186fa4b32840807a6c7092bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold (4), BEST RMSE: 1.958089492110944, BEST R2: 0.8294880226840295\n"
     ]
    }
   ],
   "source": [
    "is_holdout = False # True 를 줄 경우 hold-out 방식, False 는 교차 검증 방식\n",
    "seed_everything(CFG.seed)\n",
    "best_score1_list = []\n",
    "best_score2_list = []\n",
    "\n",
    "for i,(tri,vai) in enumerate(cv.split(train_data, groups)):\n",
    "\n",
    "    # 모델 객체 생성\n",
    "    model = Net(n_features, in_features, **hp).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=hp[\"lr\"])\n",
    "\n",
    "    # 학습용 3차원 데이터\n",
    "    x_train = train_data[tri]\n",
    "    y_train = target[tri]\n",
    "\n",
    "    # 검증용 3차원 데이터\n",
    "    x_valid = train_data[vai]\n",
    "    y_valid = target[vai]\n",
    "\n",
    "    # 학습용 2차원 데이터\n",
    "    x_train_ft = train_ft[tri]\n",
    "\n",
    "    # 검증용 2차원 데이터\n",
    "    x_valid_ft = train_ft[vai]\n",
    "\n",
    "    # 배치 단위로 학습하기 위한 pytorch의 dataset 관련 객체 생성\n",
    "    train_dt = TorchDataset(x_train,x_train_ft,y_train)\n",
    "    valid_dt = TorchDataset(x_valid,x_valid_ft,y_valid)\n",
    "    train_dl = torch.utils.data.DataLoader(train_dt, batch_size=hp[\"batch_size\"], shuffle=True)\n",
    "    valid_dl = torch.utils.data.DataLoader(valid_dt, batch_size=hp[\"batch_size\"],shuffle=False)\n",
    "\n",
    "    # 여러번 epoch 단위로 학습 수행\n",
    "    # - 조기 종료 조건을 통해 몇번 이상 성능 개선이 없을 경우 학습 중지\n",
    "    best_score1 = np.inf\n",
    "    patience = 0\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        train_loss = train_loop(train_dl, model, loss_fn,optimizer,device )\n",
    "        valid_loss , pred = test_loop(valid_dl, model, loss_fn,device  )\n",
    "\n",
    "        score1 = root_mean_squared_error(y_valid, pred )\n",
    "        score2 = r2_score(y_valid, pred )\n",
    "        patience += 1\n",
    "        if best_score1 > score1:\n",
    "            patience = 0\n",
    "            best_score1 = score1\n",
    "            best_score2 = score2\n",
    "            torch.save(model.state_dict(),f\"{CFG.model_name}-{i}.pth\") # 모델 가중치 저장\n",
    "\n",
    "        if patience == CFG.patience_limit:\n",
    "            break\n",
    "    print(f\"Fold ({i}), BEST RMSE: {best_score1}, BEST R2: {best_score2}\")\n",
    "    best_score1_list.append(best_score1)\n",
    "    best_score2_list.append(best_score2)\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if is_holdout:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "11ddfb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.6646146380185194, R2: 0.8742146856120337\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE: {np.mean(best_score1_list)}, R2: {np.mean(best_score2_list)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
